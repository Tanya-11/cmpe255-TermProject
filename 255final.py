# -*- coding: utf-8 -*-
"""255Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qn1mkTOfP_tqkvfO4Iz44K_cUmmVZ8Nw
"""

# Commented out IPython magic to ensure Python compatibility.
# Importing Libraries 
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno
# %matplotlib inline
import plotly.express as px
!pip install xgboost

from google.colab import files
uploaded = files.upload()

pd.set_option("display.max_rows", None, "display.max_columns", None)

dataset = pd.read_csv('dataset_small.csv')
df = pd.DataFrame(dataset)

dataset.head(10)

dataset.describe()

dataset.isnull().sum()

from matplotlib import style

phishing = (dataset['phishing'] == 1).sum() 

legit = (dataset['phishing'] == 0).sum()
print(f"Total phishing URL",phishing)
print(f"Total legit URL",legit)
p = [phishing, legit]
plt.pie(p,
       labels = ['Phishing', 'Legit'], 
       colors = ['red', 'green'],  
       explode = (0.15, 0),
       startangle = 0) 
plt.axis('equal') 
plt.show()

from sklearn.feature_selection import VarianceThreshold
var_thres = VarianceThreshold(threshold=0)
var_thres.fit(dataset)
var_thres.get_support()
constant_columns = [column for column in dataset.columns
                    if column not in dataset.columns[var_thres.get_support()]]
print(f"No of columns with 0 variance: {len(constant_columns)}")
constant_columns

dataset = dataset.drop(constant_columns,axis=1)
dataset.shape

#length of dataset before dropping duplicate rows
lengthbeforedropping=len(dataset)
lengthbeforedropping

# plotting count of values per columns ignoring missing values for dataset
msno.bar(dataset,color='dodgerblue', sort='ascending',log=True)

#length of dataset after dropping duplicate rows

dataset.drop_duplicates(keep=False,inplace=True)
lengthafterdropping=len(dataset)
lengthafterdropping

#Duplicate Rows
duplicaterows=lengthbeforedropping-lengthafterdropping
duplicaterows

#Replacing the value -1 with Nan and then deleting those rows

#Finding rows which contain the value -1
dataset.isin(['-1']).count()

#All the rows have the value -1 in atleast one of the columns, so lets remove the rows which have the maximum number of -1

# Data distribution of the features
cols={} 
for i in dataset.columns:
    print("- - - - - New Column Here- - - - - - - ")
    x=dataset[i].value_counts(normalize=True)
    print(x)
    if dataset[i].isin([-1]).any():
        cols[i]=x[-1]

